{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6580b30b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "built-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "train_dir = '/opt/ml/input/data/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-organizer",
   "metadata": {},
   "source": [
    "## 1. Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8e341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv_block\n",
    "# activation = relu\n",
    "# y = relu(BN(conv(x)))\n",
    "class Conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation=True, **kwargs) -> None:\n",
    "        super(Conv_block, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs) # kernel size = ...\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.activation:\n",
    "            return self.batchnorm(self.conv(x))\n",
    "        return self.relu(self.batchnorm(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15e70c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res_block(nn.Module):\n",
    "    def __init__(self, in_channels, red_channels, out_channels, is_plain=False):\n",
    "        super(Res_block,self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.is_plain = is_plain\n",
    "        \n",
    "        if in_channels==64:\n",
    "            self.convseq = nn.Sequential(\n",
    "                Conv_block(in_channels, red_channels, kernel_size=1, padding=0),\n",
    "                Conv_block(red_channels, red_channels*2, kernel_size=3, padding=1),\n",
    "                Conv_block(red_channels*2, out_channels, activation=False, kernel_size=1, padding=0)\n",
    "            )\n",
    "            self.iden = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        elif in_channels == out_channels:\n",
    "            self.convseq = nn.Sequential(\n",
    "                Conv_block(in_channels, red_channels, kernel_size=1, padding=0),\n",
    "                Conv_block(red_channels, red_channels*2, kernel_size=3, padding=1),\n",
    "                Conv_block(red_channels*2, out_channels, activation=False, kernel_size=1, padding=0)\n",
    "            )\n",
    "            self.iden = nn.Identity()\n",
    "        else:\n",
    "            self.convseq = nn.Sequential(\n",
    "                Conv_block(in_channels, red_channels, kernel_size=1, padding=0, stride=2),\n",
    "                Conv_block(red_channels, red_channels*2, kernel_size=3, padding=1),\n",
    "                Conv_block(red_channels*2, out_channels, activation=False, kernel_size=1, padding=0)\n",
    "                \n",
    "            )\n",
    "            self.iden = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.convseq(x)\n",
    "        if self.is_plain:\n",
    "            x = y\n",
    "        else:\n",
    "            x = y + self.iden(x)\n",
    "        x = self.relu(x)  # relu(skip connection)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acknowledged-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000, is_plain=False):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layers = []\n",
    "        self.ksize = 3\n",
    "        \n",
    "        #L1\n",
    "        self.conv1 = Conv_block(3,32,kernel_size=self.ksize, padding=self.ksize//2, stride=(1,1))\n",
    "        self.conv2 = Conv_block(32,64,kernel_size=self.ksize, padding=self.ksize//2, stride=(2,2))\n",
    "        #Res1 \n",
    "        self.conv3_x = nn.Sequential(\n",
    "            Res_block(64, 32, 64, is_plain)\n",
    "        )\n",
    "        #L2\n",
    "        self.conv4 = Conv_block(64,128,kernel_size=self.ksize, padding=self.ksize//2, stride=(2,2))\n",
    "        #Res2  \n",
    "        self.conv5_x = nn.Sequential(\n",
    "            Res_block(128, 64, 128, is_plain),\n",
    "            Res_block(128, 64, 128, is_plain)\n",
    "        )  \n",
    "        #L3\n",
    "        self.conv6 = Conv_block(128,256,kernel_size=self.ksize, padding=self.ksize//2, stride=(2,2))\n",
    "        #Res3  \n",
    "        self.conv7_x = nn.Sequential(\n",
    "            Res_block(256, 128, 256, is_plain),\n",
    "            Res_block(256, 128, 256, is_plain),\n",
    "            Res_block(256, 128, 256, is_plain),\n",
    "            Res_block(256, 128, 256, is_plain),\n",
    "            Res_block(256, 128, 256, is_plain),\n",
    "            Res_block(256, 128, 256, is_plain),\n",
    "            Res_block(256, 128, 256, is_plain),\n",
    "            Res_block(256, 128, 256, is_plain),\n",
    "        )\n",
    "        #L4\n",
    "        self.conv8 = Conv_block(256,512,kernel_size=self.ksize, padding=self.ksize//2, stride=(2,2))\n",
    "        #Res4\n",
    "        self.conv9_x = nn.Sequential(\n",
    "            Res_block(512, 256, 512, is_plain),\n",
    "            Res_block(512, 256, 512, is_plain),\n",
    "            Res_block(512, 256, 512, is_plain),\n",
    "            Res_block(512, 256, 512, is_plain),\n",
    "            Res_block(512, 256, 512, is_plain),\n",
    "            Res_block(512, 256, 512, is_plain),\n",
    "            Res_block(512, 256, 512, is_plain),\n",
    "            Res_block(512, 256, 512, is_plain)\n",
    "        )\n",
    "        #L5\n",
    "        self.conv10 = Conv_block(512,1024,kernel_size=self.ksize, padding=self.ksize//2, stride=(2,2))\n",
    "        #Res5\n",
    "        self.conv11_x = nn.Sequential(\n",
    "            Res_block(1024, 512, 1024, is_plain),\n",
    "            Res_block(1024, 512, 1024, is_plain),\n",
    "            Res_block(1024, 512, 1024, is_plain),\n",
    "            Res_block(1024, 512, 1024, is_plain),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            # nn.Dropout(),\n",
    "            # nn.Linear(64, 32),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7_x(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9_x(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.conv11_x(x)\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-channels",
   "metadata": {},
   "source": [
    "## 2. Test Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "extensive-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, train_idx, transform):\n",
    "        self.train_idx = train_idx\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.train_idx[index][0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, train_idx[index][1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_idx)\n",
    "\n",
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, img_paths, transform):\n",
    "#         self.img_paths = img_paths\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image = Image.open(self.img_paths[index])\n",
    "\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a781731f",
   "metadata": {},
   "source": [
    "### Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28bbea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "# 7 : 3 비율로 나눕니다.\n",
    "# submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "# submission_train = submission[:int(len(submission)*0.7)]\n",
    "# submission_test = submission[int(len(submission)*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80ad69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.read_csv(os.path.join(train_dir, 'train_label.csv'))\n",
    "image_dir = os.path.join(train_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "# image_paths = [os.path.join(image_dir, img_id) for img_id in submission.path]\n",
    "train_idx = [i for i in zip(submission.path,submission.label)]\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(256),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TrainDataset(train_idx, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = MyModel(num_classes=18).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87254af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력 크기 테스트\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 256, 256), device=device.type) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6d25446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def func_eval(model,data_iter,device):\n",
    "    with torch.no_grad():\n",
    "        n_total,n_correct = 0,0\n",
    "        model.eval() # evaluate (affects DropOut and BN)\n",
    "        for image, target in data_iter:\n",
    "            y_trgt = target.to(device)\n",
    "            model_pred = model(image.view(-1,1,28,28).to(device))\n",
    "            _,y_pred = torch.max(model_pred.data,1)\n",
    "            n_correct += (y_pred==y_trgt).sum().item()\n",
    "            n_total += image.size(0)\n",
    "        val_accr = (n_correct/n_total)\n",
    "        model.train() # back to train mode \n",
    "    return val_accr\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "341b44c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 1.7157,  1.6569,  1.5980,  ...,  1.2059,  1.1863,  1.1471],\n",
       "           [ 1.7941,  1.7745,  1.7157,  ...,  1.1667,  1.1667,  1.1275],\n",
       "           [ 1.8922,  1.8725,  1.8333,  ...,  1.1275,  1.1275,  1.1078],\n",
       "           ...,\n",
       "           [-0.6569, -0.6961, -0.7549,  ..., -0.4216, -0.4216, -0.4020],\n",
       "           [-0.6765, -0.7157, -0.7745,  ..., -0.4412, -0.4608, -0.5000],\n",
       "           [-0.6765, -0.7157, -0.7941,  ..., -0.4412, -0.4804, -0.5588]],\n",
       " \n",
       "          [[ 1.2255,  1.1667,  1.1078,  ...,  0.8725,  0.8529,  0.8137],\n",
       "           [ 1.3039,  1.2843,  1.2255,  ...,  0.8333,  0.8333,  0.7941],\n",
       "           [ 1.4020,  1.3824,  1.3431,  ...,  0.7941,  0.7941,  0.7745],\n",
       "           ...,\n",
       "           [-0.7549, -0.7941, -0.8529,  ..., -0.5000, -0.5000, -0.4804],\n",
       "           [-0.7745, -0.8137, -0.8725,  ..., -0.5196, -0.5392, -0.5784],\n",
       "           [-0.7745, -0.8137, -0.8922,  ..., -0.5196, -0.5588, -0.6373]],\n",
       " \n",
       "          [[ 0.6176,  0.5588,  0.5000,  ...,  0.2843,  0.2647,  0.2255],\n",
       "           [ 0.6961,  0.6765,  0.6176,  ...,  0.2451,  0.2451,  0.2059],\n",
       "           [ 0.7941,  0.7745,  0.7353,  ...,  0.2059,  0.2059,  0.1863],\n",
       "           ...,\n",
       "           [-0.6765, -0.7157, -0.7745,  ..., -0.4804, -0.4804, -0.4608],\n",
       "           [-0.6961, -0.7353, -0.7941,  ..., -0.5000, -0.5196, -0.5588],\n",
       "           [-0.6961, -0.7353, -0.8137,  ..., -0.5000, -0.5392, -0.6176]]]]),\n",
       " tensor([1])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2a750a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training.\n"
     ]
    }
   ],
   "source": [
    "print (\"Start training.\")\n",
    "optm = optim.Adam(model.parameters(),lr=1e-3)\n",
    "#optm = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# model.init_param() # initialize parameters\n",
    "model.train() # to train mode \n",
    "EPOCHS,print_every = 10,1\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_val_sum = 0\n",
    "    for images, target in loader:\n",
    "        # Forward path\n",
    "        y_pred = model.forward(images.to(device))\n",
    "        loss_out = loss(y_pred,target.to(device))\n",
    "        # Update\n",
    "        optm.zero_grad()     # reset gradient \n",
    "        loss_out.backward()      # backpropagate\n",
    "        optm.step()      # optimizer update\n",
    "        loss_val_sum += loss_out\n",
    "    loss_val_avg = loss_val_sum/len(loader)\n",
    "    # Print\n",
    "    if ((epoch%print_every)==0) or (epoch==(EPOCHS-1)):\n",
    "        train_accr = func_eval(model,loader,device)\n",
    "        #test_accr = func_eval(model,test_iter,device)\n",
    "        print (\"epoch:[%d] loss:[%.3f] train_accr:[%.3f]\"%\n",
    "               (epoch,loss_val_avg,train_accr))\n",
    "        # print (\"epoch:[%d] loss:[%.3f] train_accr:[%.3f] test_accr:[%.3f].\"%\n",
    "        #        (epoch,loss_val_avg,train_accr,test_accr))\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-feelings",
   "metadata": {},
   "source": [
    "## 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coral-shade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "verbal-sample",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d7e1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 256, 256]             896\n",
      "       BatchNorm2d-2         [-1, 32, 256, 256]              64\n",
      "              ReLU-3         [-1, 32, 256, 256]               0\n",
      "        Conv_block-4         [-1, 32, 256, 256]               0\n",
      "            Conv2d-5         [-1, 64, 128, 128]          18,496\n",
      "       BatchNorm2d-6         [-1, 64, 128, 128]             128\n",
      "              ReLU-7         [-1, 64, 128, 128]               0\n",
      "        Conv_block-8         [-1, 64, 128, 128]               0\n",
      "            Conv2d-9         [-1, 32, 128, 128]           2,080\n",
      "      BatchNorm2d-10         [-1, 32, 128, 128]              64\n",
      "             ReLU-11         [-1, 32, 128, 128]               0\n",
      "       Conv_block-12         [-1, 32, 128, 128]               0\n",
      "           Conv2d-13         [-1, 64, 128, 128]          18,496\n",
      "      BatchNorm2d-14         [-1, 64, 128, 128]             128\n",
      "             ReLU-15         [-1, 64, 128, 128]               0\n",
      "       Conv_block-16         [-1, 64, 128, 128]               0\n",
      "           Conv2d-17         [-1, 64, 128, 128]           4,160\n",
      "      BatchNorm2d-18         [-1, 64, 128, 128]             128\n",
      "       Conv_block-19         [-1, 64, 128, 128]               0\n",
      "           Conv2d-20         [-1, 64, 128, 128]           4,160\n",
      "             ReLU-21         [-1, 64, 128, 128]               0\n",
      "        Res_block-22         [-1, 64, 128, 128]               0\n",
      "           Conv2d-23          [-1, 128, 64, 64]          73,856\n",
      "      BatchNorm2d-24          [-1, 128, 64, 64]             256\n",
      "             ReLU-25          [-1, 128, 64, 64]               0\n",
      "       Conv_block-26          [-1, 128, 64, 64]               0\n",
      "           Conv2d-27           [-1, 64, 64, 64]           8,256\n",
      "      BatchNorm2d-28           [-1, 64, 64, 64]             128\n",
      "             ReLU-29           [-1, 64, 64, 64]               0\n",
      "       Conv_block-30           [-1, 64, 64, 64]               0\n",
      "           Conv2d-31          [-1, 128, 64, 64]          73,856\n",
      "      BatchNorm2d-32          [-1, 128, 64, 64]             256\n",
      "             ReLU-33          [-1, 128, 64, 64]               0\n",
      "       Conv_block-34          [-1, 128, 64, 64]               0\n",
      "           Conv2d-35          [-1, 128, 64, 64]          16,512\n",
      "      BatchNorm2d-36          [-1, 128, 64, 64]             256\n",
      "       Conv_block-37          [-1, 128, 64, 64]               0\n",
      "         Identity-38          [-1, 128, 64, 64]               0\n",
      "             ReLU-39          [-1, 128, 64, 64]               0\n",
      "        Res_block-40          [-1, 128, 64, 64]               0\n",
      "           Conv2d-41           [-1, 64, 64, 64]           8,256\n",
      "      BatchNorm2d-42           [-1, 64, 64, 64]             128\n",
      "             ReLU-43           [-1, 64, 64, 64]               0\n",
      "       Conv_block-44           [-1, 64, 64, 64]               0\n",
      "           Conv2d-45          [-1, 128, 64, 64]          73,856\n",
      "      BatchNorm2d-46          [-1, 128, 64, 64]             256\n",
      "             ReLU-47          [-1, 128, 64, 64]               0\n",
      "       Conv_block-48          [-1, 128, 64, 64]               0\n",
      "           Conv2d-49          [-1, 128, 64, 64]          16,512\n",
      "      BatchNorm2d-50          [-1, 128, 64, 64]             256\n",
      "       Conv_block-51          [-1, 128, 64, 64]               0\n",
      "         Identity-52          [-1, 128, 64, 64]               0\n",
      "             ReLU-53          [-1, 128, 64, 64]               0\n",
      "        Res_block-54          [-1, 128, 64, 64]               0\n",
      "           Conv2d-55          [-1, 256, 32, 32]         295,168\n",
      "      BatchNorm2d-56          [-1, 256, 32, 32]             512\n",
      "             ReLU-57          [-1, 256, 32, 32]               0\n",
      "       Conv_block-58          [-1, 256, 32, 32]               0\n",
      "           Conv2d-59          [-1, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-60          [-1, 128, 32, 32]             256\n",
      "             ReLU-61          [-1, 128, 32, 32]               0\n",
      "       Conv_block-62          [-1, 128, 32, 32]               0\n",
      "           Conv2d-63          [-1, 256, 32, 32]         295,168\n",
      "      BatchNorm2d-64          [-1, 256, 32, 32]             512\n",
      "             ReLU-65          [-1, 256, 32, 32]               0\n",
      "       Conv_block-66          [-1, 256, 32, 32]               0\n",
      "           Conv2d-67          [-1, 256, 32, 32]          65,792\n",
      "      BatchNorm2d-68          [-1, 256, 32, 32]             512\n",
      "       Conv_block-69          [-1, 256, 32, 32]               0\n",
      "         Identity-70          [-1, 256, 32, 32]               0\n",
      "             ReLU-71          [-1, 256, 32, 32]               0\n",
      "        Res_block-72          [-1, 256, 32, 32]               0\n",
      "           Conv2d-73          [-1, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-74          [-1, 128, 32, 32]             256\n",
      "             ReLU-75          [-1, 128, 32, 32]               0\n",
      "       Conv_block-76          [-1, 128, 32, 32]               0\n",
      "           Conv2d-77          [-1, 256, 32, 32]         295,168\n",
      "      BatchNorm2d-78          [-1, 256, 32, 32]             512\n",
      "             ReLU-79          [-1, 256, 32, 32]               0\n",
      "       Conv_block-80          [-1, 256, 32, 32]               0\n",
      "           Conv2d-81          [-1, 256, 32, 32]          65,792\n",
      "      BatchNorm2d-82          [-1, 256, 32, 32]             512\n",
      "       Conv_block-83          [-1, 256, 32, 32]               0\n",
      "         Identity-84          [-1, 256, 32, 32]               0\n",
      "             ReLU-85          [-1, 256, 32, 32]               0\n",
      "        Res_block-86          [-1, 256, 32, 32]               0\n",
      "           Conv2d-87          [-1, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-88          [-1, 128, 32, 32]             256\n",
      "             ReLU-89          [-1, 128, 32, 32]               0\n",
      "       Conv_block-90          [-1, 128, 32, 32]               0\n",
      "           Conv2d-91          [-1, 256, 32, 32]         295,168\n",
      "      BatchNorm2d-92          [-1, 256, 32, 32]             512\n",
      "             ReLU-93          [-1, 256, 32, 32]               0\n",
      "       Conv_block-94          [-1, 256, 32, 32]               0\n",
      "           Conv2d-95          [-1, 256, 32, 32]          65,792\n",
      "      BatchNorm2d-96          [-1, 256, 32, 32]             512\n",
      "       Conv_block-97          [-1, 256, 32, 32]               0\n",
      "         Identity-98          [-1, 256, 32, 32]               0\n",
      "             ReLU-99          [-1, 256, 32, 32]               0\n",
      "       Res_block-100          [-1, 256, 32, 32]               0\n",
      "          Conv2d-101          [-1, 128, 32, 32]          32,896\n",
      "     BatchNorm2d-102          [-1, 128, 32, 32]             256\n",
      "            ReLU-103          [-1, 128, 32, 32]               0\n",
      "      Conv_block-104          [-1, 128, 32, 32]               0\n",
      "          Conv2d-105          [-1, 256, 32, 32]         295,168\n",
      "     BatchNorm2d-106          [-1, 256, 32, 32]             512\n",
      "            ReLU-107          [-1, 256, 32, 32]               0\n",
      "      Conv_block-108          [-1, 256, 32, 32]               0\n",
      "          Conv2d-109          [-1, 256, 32, 32]          65,792\n",
      "     BatchNorm2d-110          [-1, 256, 32, 32]             512\n",
      "      Conv_block-111          [-1, 256, 32, 32]               0\n",
      "        Identity-112          [-1, 256, 32, 32]               0\n",
      "            ReLU-113          [-1, 256, 32, 32]               0\n",
      "       Res_block-114          [-1, 256, 32, 32]               0\n",
      "          Conv2d-115          [-1, 128, 32, 32]          32,896\n",
      "     BatchNorm2d-116          [-1, 128, 32, 32]             256\n",
      "            ReLU-117          [-1, 128, 32, 32]               0\n",
      "      Conv_block-118          [-1, 128, 32, 32]               0\n",
      "          Conv2d-119          [-1, 256, 32, 32]         295,168\n",
      "     BatchNorm2d-120          [-1, 256, 32, 32]             512\n",
      "            ReLU-121          [-1, 256, 32, 32]               0\n",
      "      Conv_block-122          [-1, 256, 32, 32]               0\n",
      "          Conv2d-123          [-1, 256, 32, 32]          65,792\n",
      "     BatchNorm2d-124          [-1, 256, 32, 32]             512\n",
      "      Conv_block-125          [-1, 256, 32, 32]               0\n",
      "        Identity-126          [-1, 256, 32, 32]               0\n",
      "            ReLU-127          [-1, 256, 32, 32]               0\n",
      "       Res_block-128          [-1, 256, 32, 32]               0\n",
      "          Conv2d-129          [-1, 128, 32, 32]          32,896\n",
      "     BatchNorm2d-130          [-1, 128, 32, 32]             256\n",
      "            ReLU-131          [-1, 128, 32, 32]               0\n",
      "      Conv_block-132          [-1, 128, 32, 32]               0\n",
      "          Conv2d-133          [-1, 256, 32, 32]         295,168\n",
      "     BatchNorm2d-134          [-1, 256, 32, 32]             512\n",
      "            ReLU-135          [-1, 256, 32, 32]               0\n",
      "      Conv_block-136          [-1, 256, 32, 32]               0\n",
      "          Conv2d-137          [-1, 256, 32, 32]          65,792\n",
      "     BatchNorm2d-138          [-1, 256, 32, 32]             512\n",
      "      Conv_block-139          [-1, 256, 32, 32]               0\n",
      "        Identity-140          [-1, 256, 32, 32]               0\n",
      "            ReLU-141          [-1, 256, 32, 32]               0\n",
      "       Res_block-142          [-1, 256, 32, 32]               0\n",
      "          Conv2d-143          [-1, 128, 32, 32]          32,896\n",
      "     BatchNorm2d-144          [-1, 128, 32, 32]             256\n",
      "            ReLU-145          [-1, 128, 32, 32]               0\n",
      "      Conv_block-146          [-1, 128, 32, 32]               0\n",
      "          Conv2d-147          [-1, 256, 32, 32]         295,168\n",
      "     BatchNorm2d-148          [-1, 256, 32, 32]             512\n",
      "            ReLU-149          [-1, 256, 32, 32]               0\n",
      "      Conv_block-150          [-1, 256, 32, 32]               0\n",
      "          Conv2d-151          [-1, 256, 32, 32]          65,792\n",
      "     BatchNorm2d-152          [-1, 256, 32, 32]             512\n",
      "      Conv_block-153          [-1, 256, 32, 32]               0\n",
      "        Identity-154          [-1, 256, 32, 32]               0\n",
      "            ReLU-155          [-1, 256, 32, 32]               0\n",
      "       Res_block-156          [-1, 256, 32, 32]               0\n",
      "          Conv2d-157          [-1, 128, 32, 32]          32,896\n",
      "     BatchNorm2d-158          [-1, 128, 32, 32]             256\n",
      "            ReLU-159          [-1, 128, 32, 32]               0\n",
      "      Conv_block-160          [-1, 128, 32, 32]               0\n",
      "          Conv2d-161          [-1, 256, 32, 32]         295,168\n",
      "     BatchNorm2d-162          [-1, 256, 32, 32]             512\n",
      "            ReLU-163          [-1, 256, 32, 32]               0\n",
      "      Conv_block-164          [-1, 256, 32, 32]               0\n",
      "          Conv2d-165          [-1, 256, 32, 32]          65,792\n",
      "     BatchNorm2d-166          [-1, 256, 32, 32]             512\n",
      "      Conv_block-167          [-1, 256, 32, 32]               0\n",
      "        Identity-168          [-1, 256, 32, 32]               0\n",
      "            ReLU-169          [-1, 256, 32, 32]               0\n",
      "       Res_block-170          [-1, 256, 32, 32]               0\n",
      "          Conv2d-171          [-1, 512, 16, 16]       1,180,160\n",
      "     BatchNorm2d-172          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-173          [-1, 512, 16, 16]               0\n",
      "      Conv_block-174          [-1, 512, 16, 16]               0\n",
      "          Conv2d-175          [-1, 256, 16, 16]         131,328\n",
      "     BatchNorm2d-176          [-1, 256, 16, 16]             512\n",
      "            ReLU-177          [-1, 256, 16, 16]               0\n",
      "      Conv_block-178          [-1, 256, 16, 16]               0\n",
      "          Conv2d-179          [-1, 512, 16, 16]       1,180,160\n",
      "     BatchNorm2d-180          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-181          [-1, 512, 16, 16]               0\n",
      "      Conv_block-182          [-1, 512, 16, 16]               0\n",
      "          Conv2d-183          [-1, 512, 16, 16]         262,656\n",
      "     BatchNorm2d-184          [-1, 512, 16, 16]           1,024\n",
      "      Conv_block-185          [-1, 512, 16, 16]               0\n",
      "        Identity-186          [-1, 512, 16, 16]               0\n",
      "            ReLU-187          [-1, 512, 16, 16]               0\n",
      "       Res_block-188          [-1, 512, 16, 16]               0\n",
      "          Conv2d-189          [-1, 256, 16, 16]         131,328\n",
      "     BatchNorm2d-190          [-1, 256, 16, 16]             512\n",
      "            ReLU-191          [-1, 256, 16, 16]               0\n",
      "      Conv_block-192          [-1, 256, 16, 16]               0\n",
      "          Conv2d-193          [-1, 512, 16, 16]       1,180,160\n",
      "     BatchNorm2d-194          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-195          [-1, 512, 16, 16]               0\n",
      "      Conv_block-196          [-1, 512, 16, 16]               0\n",
      "          Conv2d-197          [-1, 512, 16, 16]         262,656\n",
      "     BatchNorm2d-198          [-1, 512, 16, 16]           1,024\n",
      "      Conv_block-199          [-1, 512, 16, 16]               0\n",
      "        Identity-200          [-1, 512, 16, 16]               0\n",
      "            ReLU-201          [-1, 512, 16, 16]               0\n",
      "       Res_block-202          [-1, 512, 16, 16]               0\n",
      "          Conv2d-203          [-1, 256, 16, 16]         131,328\n",
      "     BatchNorm2d-204          [-1, 256, 16, 16]             512\n",
      "            ReLU-205          [-1, 256, 16, 16]               0\n",
      "      Conv_block-206          [-1, 256, 16, 16]               0\n",
      "          Conv2d-207          [-1, 512, 16, 16]       1,180,160\n",
      "     BatchNorm2d-208          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-209          [-1, 512, 16, 16]               0\n",
      "      Conv_block-210          [-1, 512, 16, 16]               0\n",
      "          Conv2d-211          [-1, 512, 16, 16]         262,656\n",
      "     BatchNorm2d-212          [-1, 512, 16, 16]           1,024\n",
      "      Conv_block-213          [-1, 512, 16, 16]               0\n",
      "        Identity-214          [-1, 512, 16, 16]               0\n",
      "            ReLU-215          [-1, 512, 16, 16]               0\n",
      "       Res_block-216          [-1, 512, 16, 16]               0\n",
      "          Conv2d-217          [-1, 256, 16, 16]         131,328\n",
      "     BatchNorm2d-218          [-1, 256, 16, 16]             512\n",
      "            ReLU-219          [-1, 256, 16, 16]               0\n",
      "      Conv_block-220          [-1, 256, 16, 16]               0\n",
      "          Conv2d-221          [-1, 512, 16, 16]       1,180,160\n",
      "     BatchNorm2d-222          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-223          [-1, 512, 16, 16]               0\n",
      "      Conv_block-224          [-1, 512, 16, 16]               0\n",
      "          Conv2d-225          [-1, 512, 16, 16]         262,656\n",
      "     BatchNorm2d-226          [-1, 512, 16, 16]           1,024\n",
      "      Conv_block-227          [-1, 512, 16, 16]               0\n",
      "        Identity-228          [-1, 512, 16, 16]               0\n",
      "            ReLU-229          [-1, 512, 16, 16]               0\n",
      "       Res_block-230          [-1, 512, 16, 16]               0\n",
      "          Conv2d-231          [-1, 256, 16, 16]         131,328\n",
      "     BatchNorm2d-232          [-1, 256, 16, 16]             512\n",
      "            ReLU-233          [-1, 256, 16, 16]               0\n",
      "      Conv_block-234          [-1, 256, 16, 16]               0\n",
      "          Conv2d-235          [-1, 512, 16, 16]       1,180,160\n",
      "     BatchNorm2d-236          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-237          [-1, 512, 16, 16]               0\n",
      "      Conv_block-238          [-1, 512, 16, 16]               0\n",
      "          Conv2d-239          [-1, 512, 16, 16]         262,656\n",
      "     BatchNorm2d-240          [-1, 512, 16, 16]           1,024\n",
      "      Conv_block-241          [-1, 512, 16, 16]               0\n",
      "        Identity-242          [-1, 512, 16, 16]               0\n",
      "            ReLU-243          [-1, 512, 16, 16]               0\n",
      "       Res_block-244          [-1, 512, 16, 16]               0\n",
      "          Conv2d-245          [-1, 256, 16, 16]         131,328\n",
      "     BatchNorm2d-246          [-1, 256, 16, 16]             512\n",
      "            ReLU-247          [-1, 256, 16, 16]               0\n",
      "      Conv_block-248          [-1, 256, 16, 16]               0\n",
      "          Conv2d-249          [-1, 512, 16, 16]       1,180,160\n",
      "     BatchNorm2d-250          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-251          [-1, 512, 16, 16]               0\n",
      "      Conv_block-252          [-1, 512, 16, 16]               0\n",
      "          Conv2d-253          [-1, 512, 16, 16]         262,656\n",
      "     BatchNorm2d-254          [-1, 512, 16, 16]           1,024\n",
      "      Conv_block-255          [-1, 512, 16, 16]               0\n",
      "        Identity-256          [-1, 512, 16, 16]               0\n",
      "            ReLU-257          [-1, 512, 16, 16]               0\n",
      "       Res_block-258          [-1, 512, 16, 16]               0\n",
      "          Conv2d-259          [-1, 256, 16, 16]         131,328\n",
      "     BatchNorm2d-260          [-1, 256, 16, 16]             512\n",
      "            ReLU-261          [-1, 256, 16, 16]               0\n",
      "      Conv_block-262          [-1, 256, 16, 16]               0\n",
      "          Conv2d-263          [-1, 512, 16, 16]       1,180,160\n",
      "     BatchNorm2d-264          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-265          [-1, 512, 16, 16]               0\n",
      "      Conv_block-266          [-1, 512, 16, 16]               0\n",
      "          Conv2d-267          [-1, 512, 16, 16]         262,656\n",
      "     BatchNorm2d-268          [-1, 512, 16, 16]           1,024\n",
      "      Conv_block-269          [-1, 512, 16, 16]               0\n",
      "        Identity-270          [-1, 512, 16, 16]               0\n",
      "            ReLU-271          [-1, 512, 16, 16]               0\n",
      "       Res_block-272          [-1, 512, 16, 16]               0\n",
      "          Conv2d-273          [-1, 256, 16, 16]         131,328\n",
      "     BatchNorm2d-274          [-1, 256, 16, 16]             512\n",
      "            ReLU-275          [-1, 256, 16, 16]               0\n",
      "      Conv_block-276          [-1, 256, 16, 16]               0\n",
      "          Conv2d-277          [-1, 512, 16, 16]       1,180,160\n",
      "     BatchNorm2d-278          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-279          [-1, 512, 16, 16]               0\n",
      "      Conv_block-280          [-1, 512, 16, 16]               0\n",
      "          Conv2d-281          [-1, 512, 16, 16]         262,656\n",
      "     BatchNorm2d-282          [-1, 512, 16, 16]           1,024\n",
      "      Conv_block-283          [-1, 512, 16, 16]               0\n",
      "        Identity-284          [-1, 512, 16, 16]               0\n",
      "            ReLU-285          [-1, 512, 16, 16]               0\n",
      "       Res_block-286          [-1, 512, 16, 16]               0\n",
      "          Conv2d-287           [-1, 1024, 8, 8]       4,719,616\n",
      "     BatchNorm2d-288           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-289           [-1, 1024, 8, 8]               0\n",
      "      Conv_block-290           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-291            [-1, 512, 8, 8]         524,800\n",
      "     BatchNorm2d-292            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-293            [-1, 512, 8, 8]               0\n",
      "      Conv_block-294            [-1, 512, 8, 8]               0\n",
      "          Conv2d-295           [-1, 1024, 8, 8]       4,719,616\n",
      "     BatchNorm2d-296           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-297           [-1, 1024, 8, 8]               0\n",
      "      Conv_block-298           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-299           [-1, 1024, 8, 8]       1,049,600\n",
      "     BatchNorm2d-300           [-1, 1024, 8, 8]           2,048\n",
      "      Conv_block-301           [-1, 1024, 8, 8]               0\n",
      "        Identity-302           [-1, 1024, 8, 8]               0\n",
      "            ReLU-303           [-1, 1024, 8, 8]               0\n",
      "       Res_block-304           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-305            [-1, 512, 8, 8]         524,800\n",
      "     BatchNorm2d-306            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-307            [-1, 512, 8, 8]               0\n",
      "      Conv_block-308            [-1, 512, 8, 8]               0\n",
      "          Conv2d-309           [-1, 1024, 8, 8]       4,719,616\n",
      "     BatchNorm2d-310           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-311           [-1, 1024, 8, 8]               0\n",
      "      Conv_block-312           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-313           [-1, 1024, 8, 8]       1,049,600\n",
      "     BatchNorm2d-314           [-1, 1024, 8, 8]           2,048\n",
      "      Conv_block-315           [-1, 1024, 8, 8]               0\n",
      "        Identity-316           [-1, 1024, 8, 8]               0\n",
      "            ReLU-317           [-1, 1024, 8, 8]               0\n",
      "       Res_block-318           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-319            [-1, 512, 8, 8]         524,800\n",
      "     BatchNorm2d-320            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-321            [-1, 512, 8, 8]               0\n",
      "      Conv_block-322            [-1, 512, 8, 8]               0\n",
      "          Conv2d-323           [-1, 1024, 8, 8]       4,719,616\n",
      "     BatchNorm2d-324           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-325           [-1, 1024, 8, 8]               0\n",
      "      Conv_block-326           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-327           [-1, 1024, 8, 8]       1,049,600\n",
      "     BatchNorm2d-328           [-1, 1024, 8, 8]           2,048\n",
      "      Conv_block-329           [-1, 1024, 8, 8]               0\n",
      "        Identity-330           [-1, 1024, 8, 8]               0\n",
      "            ReLU-331           [-1, 1024, 8, 8]               0\n",
      "       Res_block-332           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-333            [-1, 512, 8, 8]         524,800\n",
      "     BatchNorm2d-334            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-335            [-1, 512, 8, 8]               0\n",
      "      Conv_block-336            [-1, 512, 8, 8]               0\n",
      "          Conv2d-337           [-1, 1024, 8, 8]       4,719,616\n",
      "     BatchNorm2d-338           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-339           [-1, 1024, 8, 8]               0\n",
      "      Conv_block-340           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-341           [-1, 1024, 8, 8]       1,049,600\n",
      "     BatchNorm2d-342           [-1, 1024, 8, 8]           2,048\n",
      "      Conv_block-343           [-1, 1024, 8, 8]               0\n",
      "        Identity-344           [-1, 1024, 8, 8]               0\n",
      "            ReLU-345           [-1, 1024, 8, 8]               0\n",
      "       Res_block-346           [-1, 1024, 8, 8]               0\n",
      "AdaptiveAvgPool2d-347           [-1, 1024, 1, 1]               0\n",
      "          Linear-348                   [-1, 18]          18,450\n",
      "================================================================\n",
      "Total params: 47,509,682\n",
      "Trainable params: 47,509,682\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 630.01\n",
      "Params size (MB): 181.24\n",
      "Estimated Total Size (MB): 811.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c1fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
